\documentclass[titlepage]{article}
\author{Michael Lundquist}
\title{Research Interest Narrative}

%******* bibliography
\usepackage[backend=biber,style=apa]{biblatex}
%\usepackage{url, apacite}
%for some reason, url doesn't work with biblatex
\addbibresource{finalPaperDraft.bib}

%******* math
%https://tex.stackexchange.com/questions/41035/what-is-causing-undefined-control-sequence
\usepackage{amsmath}

%****** for double spacing
\usepackage{setspace}
%\singlespacing
%\onehalfspacing
\doublespacing
%\setstretch{1.1}

%****** titles
\usepackage[explicit]{titlesec}
\usepackage{ulem}
\usepackage{lipsum}% just to generate text for the example

\setcounter{secnumdepth}{4}
\titleformat{\paragraph}[runin]
  {\normalfont\normalsize\bfseries}{}{15pt}{\uline{\theparagraph\hspace*{1em}#1.}}
\titleformat{name=\paragraph,numberless}[runin]
  {\normalfont\normalsize\bfseries}{}{15pt}{\uline{#1.}}



% ******** graphviz highlighting def ********
\usepackage[pdf]{graphviz}
% ******** end graphviz highlighting def ********


\begin{document}

\maketitle

%*****************TITLE PAGE IS MADE************

\section{Introduction}

In modern computing, multi-core processors are almost ubiquitous. Even the 35\$ Raspberry Pi 3 B+ comes equip with a quad-core processor. This new paradigm of computing comes with new challenges, but grand new possibilities. This paper covers some common possibilities, challenges and solutions to the challenges faced in this new environment. When applicable, this paper has tested java programs to demonstrate some of these concepts.

\subsection{Possibilities}

Having multi-core processors allows multiple processes to run \textit{in parallel}. When multiple processes run in parallel, their programs \textit{speed up}. However, in many situations, programs can't run in parallel for various reasons. Still, the multi-core architecture can speed up non-parallel tasks by diverting them to core that runs at a faster speed. Truly, multiple cores is here to stay.

\subsection{Amdahl's Law}

Amdahl's law\footcite[the cited paper is the law's origin]{Amdahl:1967:VSP:1465482.1465560} is a formula for calculating how much a program speeds up. We say a program with $n$ processors speeds up $S$ times. This formula also has the factor $p$, which is the ratio of the program that can be run in parallel. If $p =.98$, $98\%$ of the program can be run in parallel.

$S = \dfrac 1 {1 - p + \dfrac p n}$

This law provides a quick and dirty approach to determining if it's worth it to run a program on a multi-cored system. Furthermore, it has some surprising results. For example, if $95\%$ of a program can be parallelized, and you run it on a 1080Ti with its $57344$ threads, you only see a speed up of about 20. While $S$ was only 20 in the last example, $\dfrac p n$ ran \textit{nearly instantly}. With this information, our goal is to maximize $p$. \footcite[Stackoverflow user, djna, helps another user, Monster, maximize $p$]{stack:xxx}

\section{Challenges}

Speedup through parallelization is fantastic, but parallelization naturally comes with new challenges. For example, work coordination takes on a new form in multi-threaded applications where threads must be persistently independent and isolated, but still coordinate the use or resources. This section will discuss these challenges and discuss some requirements that programmers use to avoid these challenges. Finally this section will provide a sample solution to the dining philosophers problem\footcite[produced by dijkstra]{Dijkstra:1965:CSP:1102034} that demonstrates a situation where these issues could arise.


\subsection{deadlock}

Deadlocks occur when a thread is permanently blocked from executing (entering its critical section) by other threads. Without locks (see below), this would happen when multiple processes can't resolve competitions for resources. To prevent deadlock, programmers grant mutually exclusive access to resources. When a program has mutually exclusive access to a resource, it's said to be in its \textit{critical section}.

A critical section is \textit{well formed} if it has the following three properties. First, it has its own unique lock. Each process needs its own lock to prevent \textit{covering states} where the thread is about to use a resource, but has no way of telling other threads about this intention. Second, the thread lock when entering their critical section to ensure mutual exclusion. Third, threads unlock when exiting their critical section to allow other threads to ensure mutual exclusion.


\subsection{starvation}

The last requirement of a well-formed critical section to unlock prevents \textit{starvation}. Starvation is when a thread a process can't \textit{ever} enter its critical section. Freedom from starvation is guaranteed if your program has no deadlocks and threads enter their respective critical sections in a first-come first-serve order. Note, freedom from starvation is important, but not always guaranteed.

\subsection{fairness}

If a thread is starvation free, it will eventually execute, but for a thread to have a truly \textit{fair} (equal) chance of executing its critical section, it cannot wait an unfair amount of time. Fairness is often accomplished by putting \textit{bounds} on how long your program can wait at any point. If bounded wait times are ensured on all parts a thread's life-cycle, we call the cycle \textit{wait free}.

\subsection{Dining Philosophers Example}

The dining philosophers\footcite[original notes on concurrency from dijkstra]{Dijkstra:1965:CSP:1102034} problem is an example of how deadlock and therefore starvation could occur. In the problem a group of philosophers sit around a table and eat. The philosophers must share a chopstick with a philosopher on their right, and a philosopher on their right. If every philosopher is greedy and grabs one chopstick, deadlock will occur and the philosophers will starve and die.

My group of philosophers decided to courteous. When they sit down, they decide who starts eating. Then one at a time, the philosophers either: stop eating if they are, or tell their neighbors to stop, and take their chopstick. If a philosopher was told to stop eating, he skips his turn. The emerging behavior from this algorithm is a deadlock-free, starvation-free and fair solution where each philosopher can eat.

\iffalse
\begin{itemize}
    \item readers-writers problem (requires waiting)
    \item producer consumer (1--1) (interrupts) vs consumer consumer (M--M)(roles) (the philosophers are both)
    \item readers-writers problem (requires waiting)
\end{itemize}
\fi


\section{Solutions to Challenges}
%***********HERE'S WHERE THE PAPER really BEGINS****************
The dining philosophers problem gives an example where the challenges discussed above are faced. These challenges are regularly faced in multi-threaded programs where programs are competing for resources as the philosophers competed for chopsticks. This section will discuss some general rules and techniques for overcoming the discussed challenges. The first technique we use is locking, we then discuss protocols for avoiding the challenges.

\subsection{Locking Algorithms}

Well-formed critical sections start, lock, run, then unlock. Remember, critical sections are how mutual exclusion, a fundamental property of multi-threading is performed.  Locks are used by a thread to request entry into its critical section. If another thread is in its critical section, the lock will block the thread until the lock has determined to unblock the thread. Although locks are a simple concept, they're difficult to design. Along with the issues discussed above lock algorithms are often called simultaneously by two different threads.

\subsubsection{Filter Lock}

The filter lock uses two parallel arrays to queue threads. When a thread calls lock, it enters into level 0 of each of the arrays. If a thread is already at position 0, one of the arrays has a variable to detect this and the thread that's currently at position 0 gets bumped up to the next position. As you can see, it's very important to have enough space for each thread. While the position ahead of the current thread is open, thread moves up to that position. Eventually, the thread hits the last position in the arrays and runs. The important thing to understand about the filter lock is deadlock-free, and first-in first-out, furthermore simultaneous calls to the filter lock are safe.

\paragraph*{Peterson Lock}

The filter lock is an adaption of the Peterson lock\footcite[{P}eterson's original paper on the Peterson lock]{PETERSON1981115} to $n$ variables. Peterson pioneered the idea of reading and writing a shared variable to prevent deadlock and flags to prevent starvation.




 % changing font
 %https://texblog.org/2012/08/29/changing-the-font-size-in-latex/



\subsection{protocols}

If all the threads and their corresponding objects follow certain protocols, then you can make certain guarantees about how the program will perform. Ultimately, the purpose of a protocol is to ensure correctness and progress.

\subsubsection{correctness (safety)}

Methods are correct if they produce the expected result. For example, a first-in first-out queue should dequeue objects in the same order they were enqueued. Methods that are correct in every defined state are called \textit{total methods} whereas methods that are only correct in some states are called \textit{partial methods}. The following are protocols that make correctness claims.

\paragraph*{Sequential}

Objects and methods that behave sequentially start, then do some processing, then end. This pattern gives programmers a simple way of understanding thread behavior.

\paragraph*{Quiescent}

Quiescent objects and methods that occur in a sequence have a waiting period between them. For example, if you enqueue, quiescence guarantees the object you enqueued is present when you dequeue.

\paragraph*{linearizability}

Methods and objects that are linearizable appear to occur instantaneously. This is the most safe but most restrictive protocol. With linearization, you can't have thread related errors, but you also can't do operations in parallel.

\subsubsection{progress}

Threads that ensure progress must at some point complete. Some protocols make progress claims by blocking, and some don't.

\paragraph{protocols that ensure progress}

Sometimes threads \textit{dependend} on the underlying operating system to ensure progress. Locks depend on the underlying operating system to prevent deadlock and starvation. Generally dependent progress conditions rely heavily on locking and mutual exclusion and are therefore blocking.

Depending on the underlying operating system is often required, but whenever possible it's best to use progress conditions that are independent of the underlying operating system. For example, if the underlying operating system gets preempted, your entire program's state could get confused. Progress conditions that don't depend on the underlying operating system are generally non-blocking

\section{conclusion}

In summary, this paper discussed the advantages of multithreading, the challenges presented by multithreading, and some ways to overcome those challenges. The paper also included code example for the reader to experiment with.


%******************REFERENCES***************
\begin{singlespace}


%https://www.latex-tutorial.com/tutorials/bibtex/
%https://www.youtube.com/watch?v=KS9GvK7cvmo
%https://tex.stackexchange.com/questions/134180/how-do-i-add-citations-at-the-end-of-the-document-as-done-here
%https://tex.stackexchange.com/questions/305381/biblatex-empty-bibliography
\newpage
\nocite{*}
\printbibliography
\end{singlespace}

\end{document}